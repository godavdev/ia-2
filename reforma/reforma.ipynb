{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuracion general\n",
    "Se configura el directorio en el donde se estara descargando la información, así como la query por la cual se guiará para buscar información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directorio de los archivos\n",
    "data_dirname = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "# Busqueda que se va a hacer\n",
    "QUERY = \"Reforma Judifical Mexico\"\n",
    "\n",
    "# Funcion para escribir un archivo de texto\n",
    "def write_txt(text:str, name:str):\n",
    "    output_file = os.path.join(data_dirname, f\"{name}.txt\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as txt_file:\n",
    "        txt_file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recoleccion de datos por paginas web\n",
    "Se utiliza BeautifulSoup para el scraping, asi como goolgesearch para hacer las busquedas, intenta encontrar el contenido más importante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al procesar https://www.dof.gob.mx/nota_detalle.php?codigo=5738985&fecha=15/09/2024: HTTPSConnectionPool(host='www.dof.gob.mx', port=443): Max retries exceeded with url: /nota_detalle.php?codigo=5738985&fecha=15/09/2024 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\n",
      "Error al procesar https://www.cjf.gob.mx/reformaPJF/: HTTPSConnectionPool(host='www.cjf.gob.mx', port=443): Max retries exceeded with url: /reformaPJF/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\n",
      "Error al procesar https://law.stanford.edu/2024/11/05/la-reforma-judicial-en-mexico-viola-obligaciones-internacionales-en-materia-de-derechos-humanos/: 403 Client Error: Forbidden for url: https://law.stanford.edu/2024/11/05/la-reforma-judicial-en-mexico-viola-obligaciones-internacionales-en-materia-de-derechos-humanos/\n",
      "Error al procesar https://www.wola.org/es/analisis/reforma-judicial-en-mexico-un-retroceso-para-los-derechos-humanos/: 403 Client Error: Forbidden for url: https://www.wola.org/es/analisis/reforma-judicial-en-mexico-un-retroceso-para-los-derechos-humanos/\n",
      "Error al procesar https://escuelajudicial.cjf.gob.mx/microSitio/: HTTPSConnectionPool(host='escuelajudicial.cjf.gob.mx', port=443): Max retries exceeded with url: /microSitio/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\n",
      "Error al procesar https://www.france24.com/es/am%C3%A9rica-latina/20240908-reforma-judicial-en-m%C3%A9xico-en-qu%C3%A9-consiste-el-proyecto-de-ley-que-divide-al-pa%C3%ADs: 403 Client Error: Forbidden for url: https://www.france24.com/es/am%C3%A9rica-latina/20240908-reforma-judicial-en-m%C3%A9xico-en-qu%C3%A9-consiste-el-proyecto-de-ley-que-divide-al-pa%C3%ADs\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from googlesearch import search\n",
    "\n",
    "\n",
    "# Funcion para buscar paginas en google\n",
    "def search_pages_google(query: str):\n",
    "    return list(search(query, num_results=30))\n",
    "\n",
    "\n",
    "# Funcion para extraer el contenido orincipal de una pagina\n",
    "def extract_page_content(url: str):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
    "            tag.decompose()\n",
    "\n",
    "        main_content = (\n",
    "            soup.find(\"main\")\n",
    "            or soup.find(\"article\")\n",
    "            or soup.find(\"div\", class_=\"content\")\n",
    "            or soup.find(\"div\", class_=\"main\")\n",
    "        )\n",
    "        if main_content:\n",
    "            return main_content.get_text(strip=True, separator=\"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Buscar en las paginas\n",
    "def search_in_pages():\n",
    "    urls = search_pages_google(f\"{QUERY} after:2024-01-01\")\n",
    "    text = \"\"\n",
    "    for url in urls:\n",
    "        content = extract_page_content(url)\n",
    "        if content:\n",
    "            text += f\"---URL: {url}\\n\"\n",
    "            text += content\n",
    "            text += \"\\n\\n\"\n",
    "    write_txt(text, \"pages\")\n",
    "\n",
    "\n",
    "search_in_pages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recolección de datos por pdf\n",
    "Usando googlesearch en conjunto con requests, se extraen pdfs que sean despues del inicio de este año, para verificar que efectivamente sea esta reforma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al descargar https://www.diputados.gob.mx/sedia/sia/spi/SAPI-ASS-11-24.pdf: HTTPSConnectionPool(host='www.diputados.gob.mx', port=443): Max retries exceeded with url: /sedia/sia/spi/SAPI-ASS-11-24.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\n",
      "Error al descargar https://escuelajudicial.cjf.gob.mx/MicroSitio/Doctos/Minuta_Reforma_Poder_Judicial.pdf: HTTPSConnectionPool(host='escuelajudicial.cjf.gob.mx', port=443): Max retries exceeded with url: /MicroSitio/Doctos/Minuta_Reforma_Poder_Judicial.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\n",
      "Error al descargar https://www.cjf.gob.mx/reformapjf/documentos/Jornadas_Nacionales_Reforma_Poder_Judicial.pdf: HTTPSConnectionPool(host='www.cjf.gob.mx', port=443): Max retries exceeded with url: /reformapjf/documentos/Jornadas_Nacionales_Reforma_Poder_Judicial.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\n",
      "Error al descargar https://www.enkoll.com/wp-content/uploads/2024/06/ENCUESTA-NACIONAL-SOBRE-LA-REFORMA-JUDICIAL-EN-MEXICO-170624.pdf: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error al descargar https://equis.org.mx/wp-content/uploads/2024/07/Reforma-Judicial-Feminista.pdf: 406 Client Error: Not Acceptable for url: https://equis.org.mx/wp-content/uploads/2024/07/Reforma-Judicial-Feminista.pdf\n",
      "Error al descargar https://iccmex.mx/posturas/solicitan-icc-global-e-icc-mexico-cautela-al-congreso-de-la-union-frente-a-reforma-judicial-por-posibles-consecuencias-internacionales.pdf: HTTPSConnectionPool(host='iccmex.mx', port=443): Max retries exceeded with url: /posturas/solicitan-icc-global-e-icc-mexico-cautela-al-congreso-de-la-union-frente-a-reforma-judicial-por-posibles-consecuencias-internacionales.pdf (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)')))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "import requests\n",
    "from googlesearch import search\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Directorio de los pdfs\n",
    "pdf_dirname = os.path.join(data_dirname, \"pdfs\")\n",
    "\n",
    "\n",
    "# Funcion para descargar un pdf\n",
    "def download_pdf(url: str):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        filename = url.split(\"/\")[-1]\n",
    "        if not filename.endswith(\".pdf\"):\n",
    "            filename += \".pdf\"\n",
    "        os.makedirs(pdf_dirname, exist_ok=True)\n",
    "        filepath = os.path.join(pdf_dirname, filename)\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        return filepath\n",
    "    except Exception as e:\n",
    "        print(f\"Error al descargar {url}: {e}\")\n",
    "\n",
    "\n",
    "# Funcion para buscar pdfs\n",
    "def search_pdfs() -> Dict[str, str]:\n",
    "    results = search(f\"{QUERY} filetype:pdf after:2024-01-01\", num_results=30)\n",
    "    results_dict = {}\n",
    "    for url in results:\n",
    "        if url.endswith(\".pdf\"):\n",
    "            result = download_pdf(url)\n",
    "            if result:\n",
    "                results_dict[url] = result\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "# Funcion para extraer texto de un pdf\n",
    "def extract_text_from_pdf(filepath: str) -> str:\n",
    "    try:\n",
    "        text = \"\"\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            reader = PdfReader(f)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "                text += \"\\n\"\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Funcion para limpiar texto\n",
    "def clean_text(text: str) -> str:\n",
    "    lines = text.splitlines()\n",
    "    cleaned_lines = [line.strip() for line in lines if line.strip()]\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "# Funcion para crear un archivo de texto con los pdfs\n",
    "def create_pdfs_txt():\n",
    "    results = search_pdfs()\n",
    "    text = \"\"\n",
    "    for key, value in results.items():\n",
    "        text += f\"---URL: {key}\\n\"\n",
    "        text += extract_text_from_pdf(value)\n",
    "        text += \"\\n\\n\"\n",
    "\n",
    "    write_txt(text, \"pdfs\")\n",
    "\n",
    "\n",
    "create_pdfs_txt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recoleccion de datos por videos\n",
    "Por medio de pytube.fix se descargan los videos, se extrae el audio del video con ffmpeg y con openai-whisper se pasa a un archivo de txt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\David\\ia\\.venv\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "# Cargar el modelo\n",
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\0.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\1.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\2.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\3.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\4.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\5.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\6.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\7.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\8.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\9.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\10.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\11.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\12.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\13.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\14.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\15.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\16.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\17.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\18.mp3\n",
      "Archivo convertido: c:\\Users\\David\\ia\\reforma\\data\\audios\\19.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    "from pytubefix.contrib.search import Search, Filter\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Directorio de los audios\n",
    "audios_dirname = os.path.join(data_dirname, \"audios\")\n",
    "\n",
    "# Funcion para convertir un archivo a mp3\n",
    "def convert_to_mp3(input_path: str, output_path: str) -> None:\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(input_path)\n",
    "        audio.export(output_path, format=\"mp3\")\n",
    "        print(f\"Archivo convertido: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al convertir el archivo: {e}\")\n",
    "\n",
    "# Funcion para descargar los videos\n",
    "def download_videos() -> Dict[str, str]:\n",
    "    results = Search(\n",
    "        query=QUERY,\n",
    "        filters={\"sort_by\": Filter.get_sort_by(\"Relevance\")},\n",
    "    )\n",
    "    i = 0\n",
    "    results_dict = {}\n",
    "    for result in results.videos:\n",
    "        try:\n",
    "            yt = YouTube(result.watch_url, on_progress_callback=on_progress)\n",
    "            video = yt.streams.get_audio_only()\n",
    "            video.download(output_path=audios_dirname, filename=f\"{i}.m4a\")\n",
    "            results_dict[result.watch_url] = os.path.join(audios_dirname, f\"{i}.m4a\")\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error al descargar el video\", e)\n",
    "\n",
    "    return results_dict\n",
    "\n",
    "# Funcion para transcribir un audio\n",
    "def transcript_audio(audio_path: str) -> str:\n",
    "    try:\n",
    "        mp3_audio_path = audio_path.replace(\".m4a\", \".mp3\")\n",
    "        convert_to_mp3(audio_path, mp3_audio_path)\n",
    "        result = model.transcribe(\n",
    "            mp3_audio_path,\n",
    "        )\n",
    "        return result[\"text\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error al transcribir el audio: {e}\")\n",
    "        return None\n",
    "\n",
    "# Funcion para buscar en los videos\n",
    "def search_in_videos():\n",
    "    results = download_videos()\n",
    "    txt = \"\"\n",
    "    for url, path in results.items():\n",
    "        text = transcript_audio(path)\n",
    "        if text:\n",
    "            txt += f\"---URL: {url}\\n\"\n",
    "            txt += text\n",
    "            txt += \"\\n\\n\"\n",
    "\n",
    "    write_txt(txt, \"audios\")\n",
    "\n",
    "\n",
    "search_in_videos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juntar todo en un mismo txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Leer los txt\n",
    "pages = open(os.path.join(data_dirname, \"pages.txt\"), \"r\", encoding=\"utf-8\").read()\n",
    "pdfs = open(os.path.join(data_dirname, \"pdfs.txt\"), \"r\", encoding=\"utf-8\").read()\n",
    "audios = open(os.path.join(data_dirname, \"audios.txt\"), \"r\", encoding=\"utf-8\").read()\n",
    "\n",
    "# Juntarlos en un mismo texto\n",
    "all_text = pages + \"\\n\\n\" + pdfs\n",
    "# + \"\\n\\n\" + audios\n",
    "\n",
    "# Guardar el texto\n",
    "write_txt(all_text, \"all_text\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
